{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/blaubach/chimes_CGD-myLLFork/dissimilarity_clustering\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(\"Current working directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data_#0000.xyz\n",
      "training_data_#0050.xyz\n",
      "training_data_#0055.xyz\n",
      "training_data_#0060.xyz\n",
      "training_data_#0075.xyz\n",
      "training_data_#0080.xyz\n",
      "training_data_#0110.xyz\n",
      "(300, 180)\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Define file paths with cwd appended\n",
    "file_path_2b = os.path.join(cwd, \"dft_pds/2b_all_pd\")\n",
    "file_path_3b = os.path.join(cwd, \"dft_pds/3b_all_pd\")\n",
    "file_path_4b = os.path.join(cwd, \"dft_pds/4b_all_pd\")\n",
    "file_path_labels = os.path.join(cwd, \"dft_pds/labels_pd\")\n",
    "file_path_natoms = os.path.join(cwd, \"test_notebooks/energies_per_atom.txt\")\n",
    "\n",
    "# Open pickle files with the updated file paths\n",
    "with open(file_path_2b, 'rb') as pickle_file:\n",
    "    pd_2b = pickle.load(pickle_file)\n",
    "\n",
    "with open(file_path_3b, 'rb') as pickle_file:\n",
    "    pd_3b = pickle.load(pickle_file)\n",
    "\n",
    "with open(file_path_4b, 'rb') as pickle_file:\n",
    "    pd_4b = pickle.load(pickle_file)\n",
    "\n",
    "with open(file_path_labels, 'rb') as pickle_file:\n",
    "    labels = pickle.load(pickle_file)\n",
    "\n",
    "natom_list = []\n",
    "\n",
    "# Open the text file for reading\n",
    "with open(file_path_natoms, 'r') as file:\n",
    "\n",
    "    # Read the contents of the file\n",
    "    lines = file.readlines()[1:]\n",
    "\n",
    "    # Iterate through each line\n",
    "    for line in lines:\n",
    "\n",
    "        # Split the line into words\n",
    "        words = line.split()\n",
    "        natoms = line.split(\"|\")[1].strip()\n",
    "\n",
    "        # Extract the last word, assuming it's a number\n",
    "        last_number = float(words[-1])\n",
    "        if words[0][-1] == 'z':\n",
    "            print(words[0])\n",
    "            continue\n",
    "        natom_list.append(natoms)\n",
    "\n",
    "natom_list = np.array(natom_list[:-10])\n",
    "\n",
    "# Combine the arrays along the second axis (axis=1)\n",
    "all_array = np.concatenate((pd_2b, pd_3b, pd_4b), axis=2)\n",
    "all_array = all_array.reshape(-1, all_array.shape[2])\n",
    "print(np.shape(all_array))\n",
    "df_fingerprints = pd.DataFrame(all_array)\n",
    "\n",
    "# # Define the column labels for each set of columns\n",
    "# column_labels_2b = [f'2B_{i}' for i in range(60)]\n",
    "# column_labels_3b = [f'3B_{i}' for i in range(60)]\n",
    "# column_labels_4b = [f'4B_{i}' for i in range(60)]\n",
    "\n",
    "# # Assign the column labels to the DataFrame\n",
    "# column_labels = column_labels_2b + column_labels_3b + column_labels_4b\n",
    "# df_fingerprints.columns = column_labels\n",
    "\n",
    "# # Add a new column \"labels\" to the DataFrame and assign the new vector to it\n",
    "# df_fingerprints['labels'] = labels\n",
    "\n",
    "# # Calculate the row-wise mean using `mean(axis=1)`\n",
    "# row_avg = df_fingerprints.mean(axis=1)\n",
    "\n",
    "# # Append the calculated row-wise mean as a new column named \"Pavg\"\n",
    "# df_fingerprints['Pavg'] = row_avg\n",
    "\n",
    "# # Calculate the row-wise standard deviation using `std(axis=1)`\n",
    "# row_std = df_fingerprints.std(axis=1)\n",
    "\n",
    "# # Append the calculated row-wise standard deviation as a new column named \"Pstd\"\n",
    "# df_fingerprints['Pstd'] = row_std\n",
    "\n",
    "# # Append Natoms to Dataframe\n",
    "# df_fingerprints['Natoms'] = natom_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.spatial.distance import cdist\n",
    "\n",
    "# def update_configuration_sets(min_pij_index, training_set, configuration_set, pij_matrix):\n",
    "#     training_set = pd.concat([training_set, pd.DataFrame([configuration_set.loc[min_pij_index]])])\n",
    "#     pij_matrix = pij_matrix.drop(min_pij_index)\n",
    "#     configuration_set.drop(min_pij_index, inplace=True)\n",
    "#     return training_set, configuration_set, pij_matrix\n",
    "\n",
    "# training_set = pd.DataFrame\n",
    "# for i, row in df_fingerprints.iterrows():\n",
    "#     # Obtain fingerprint\n",
    "#     fingerprint = row.iloc[:-4]\n",
    "\n",
    "#     # Compute distances to all clusters in the original data\n",
    "#     distances_to_clusters = cdist([fingerprint], available_cgs) # Computes the 2-norm between point and ground truth data\n",
    "\n",
    "#     # Find the index of the closest cluster in the original data\n",
    "#     farthest_index = np.argmin(distances_to_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 180)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "XB must be a 2-dimensional array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m cfg_cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cfg_cnt\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 60\u001b[0m     current_training_set, available_configurations, pij_matrix \u001b[38;5;241m=\u001b[39m construct_comparison(current_training_set, available_configurations, pij_matrix)\n\u001b[1;32m     61\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(current_training_set\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Add a horizontal red line at y=24\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 24\u001b[0m, in \u001b[0;36mconstruct_comparison\u001b[0;34m(training_set, candidates, pij_matrix)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCandidates column \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m contains non-numeric data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Compute pairwise distances\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m pij_values\u001b[38;5;241m.\u001b[39mappend(cdist([phi1_numeric], candidates_numeric))\n\u001b[1;32m     25\u001b[0m pij_matrix[column_values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m pij_values\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Calculate the average of values in each row\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scipy/spatial/distance.py:2984\u001b[0m, in \u001b[0;36mcdist\u001b[0;34m(XA, XB, metric, out, **kwargs)\u001b[0m\n\u001b[1;32m   2982\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXA must be a 2-dimensional array.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sB) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 2984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXB must be a 2-dimensional array.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   2985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m sB[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m   2986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mXA and XB must have the same number of columns \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2987\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(i.e. feature dimension.)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: XB must be a 2-dimensional array."
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def construct_comparison(training_set, candidates, pij_matrix=None):\n",
    "    column_values = training_set.index.tolist()\n",
    "    if pij_matrix is None:\n",
    "        pij_matrix = pd.DataFrame(columns=column_values)\n",
    "\n",
    "    pij_values = []\n",
    "    phi1 = training_set.iloc[-1]\n",
    "\n",
    "    # Ensure phi1 contains only numeric data\n",
    "    phi1_numeric = pd.to_numeric(phi1, errors='coerce')\n",
    "    if phi1_numeric.isnull().any():\n",
    "        raise ValueError(\"phi1 contains non-numeric data\")\n",
    "\n",
    "    # Ensure candidates contain only numeric data\n",
    "    candidates.fillna(0, inplace=True)\n",
    "    for col in candidates.columns:\n",
    "        candidates_numeric = pd.to_numeric(candidates[col], errors='coerce')\n",
    "        if candidates_numeric.isnull().any():\n",
    "            raise ValueError(f\"Candidates column '{col}' contains non-numeric data\")\n",
    "\n",
    "    # Compute pairwise distances\n",
    "    pij_values.append(cdist([phi1_numeric], candidates_numeric))\n",
    "    pij_matrix[column_values[-1]] = pij_values\n",
    "\n",
    "    # Calculate the average of values in each row\n",
    "    means = pij_matrix.mean(axis=1)\n",
    "\n",
    "    min_pij_index = means.idxmin()\n",
    "    # Update training set, configurations, and pij_matrix\n",
    "    update_training, update_configurations, update_pij_matrix = update_configuration_sets(min_pij_index, training_set, candidates, pij_matrix)\n",
    "    return update_training, update_configurations, update_pij_matrix\n",
    "\n",
    "\n",
    "def update_configuration_sets(min_pij_index, training_set, configuration_set, pij_matrix):\n",
    "    training_set = pd.concat([training_set, pd.DataFrame([configuration_set.loc[min_pij_index]])])\n",
    "    pij_matrix = pij_matrix.drop(min_pij_index)\n",
    "    configuration_set.drop(min_pij_index, inplace=True)\n",
    "    #configuration_set.reset_index(drop=True, inplace=True)  # Resetting indices without reindexing\n",
    "    return training_set, configuration_set, pij_matrix\n",
    "\n",
    "print(np.shape(df_fingerprints))\n",
    "\n",
    "# Choose arbitrary starting point\n",
    "starting_frame = 0\n",
    "phi1 = df_fingerprints.iloc[starting_frame]\n",
    "pij_matrix = None\n",
    "\n",
    "# Initialize training set\n",
    "current_training_set = pd.DataFrame(columns=df_fingerprints.columns)\n",
    "current_training_set = pd.concat([current_training_set, pd.DataFrame([phi1])])\n",
    "\n",
    "available_configurations = copy.copy(df_fingerprints)\n",
    "available_configurations.drop(starting_frame, inplace=True)\n",
    "\n",
    "# Compute pij matrix\n",
    "cfg_cnt = 50\n",
    "for i in range(cfg_cnt-1):\n",
    "    current_training_set, available_configurations, pij_matrix = construct_comparison(current_training_set, available_configurations, pij_matrix)\n",
    "plt.plot(current_training_set.index)\n",
    "# Add a horizontal red line at y=24\n",
    "plt.axhline(y=24, color='red')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
