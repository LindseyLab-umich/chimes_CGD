{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/blaubach/chimes_CGD-myLLFork/dissimilarity_clustering\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(\"Current working directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_data_#0000.xyz\n",
      "training_data_#0050.xyz\n",
      "training_data_#0055.xyz\n",
      "training_data_#0060.xyz\n",
      "training_data_#0075.xyz\n",
      "training_data_#0080.xyz\n",
      "training_data_#0110.xyz\n",
      "(300, 180)\n",
      "       2B_0      2B_1      2B_2      2B_3      2B_4      2B_5      2B_6  \\\n",
      "0  0.151940  0.079974  0.039987  0.134957  0.000000  0.039987  0.000000   \n",
      "1  0.151838  0.089548  0.030670  0.107863  0.026939  0.039628  0.000530   \n",
      "2  0.152059  0.091794  0.027968  0.104630  0.029103  0.039305  0.001128   \n",
      "3  0.113888  0.093885  0.074372  0.063481  0.048075  0.037675  0.033869   \n",
      "4  0.118745  0.094125  0.073008  0.061039  0.048168  0.036493  0.032401   \n",
      "\n",
      "       2B_7      2B_8      2B_9  ...  4B_54  4B_55  4B_56  4B_57  4B_58  \\\n",
      "0  0.059981  0.000000  0.064979  ...    0.0    0.0    0.0    0.0    0.0   \n",
      "1  0.059527  0.008709  0.053400  ...    0.0    0.0    0.0    0.0    0.0   \n",
      "2  0.058054  0.005966  0.057973  ...    0.0    0.0    0.0    0.0    0.0   \n",
      "3  0.031662  0.025958  0.021373  ...    0.0    0.0    0.0    0.0    0.0   \n",
      "4  0.030655  0.026413  0.021867  ...    0.0    0.0    0.0    0.0    0.0   \n",
      "\n",
      "   4B_59  labels      Pavg      Pstd  Natoms  \n",
      "0    0.0       0  0.016335  0.025764     216  \n",
      "1    0.0       0  0.016335  0.024411     216  \n",
      "2    0.0       0  0.016335  0.024316     216  \n",
      "3    0.0       0  0.016348  0.020050     216  \n",
      "4    0.0       0  0.016344  0.020228     216  \n",
      "\n",
      "[5 rows x 184 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Define file paths with cwd appended\n",
    "file_path_2b = os.path.join(cwd, \"dft_pds/2b_all_pd\")\n",
    "file_path_3b = os.path.join(cwd, \"dft_pds/3b_all_pd\")\n",
    "file_path_4b = os.path.join(cwd, \"dft_pds/4b_all_pd\")\n",
    "file_path_labels = os.path.join(cwd, \"dft_pds/labels_pd\")\n",
    "file_path_natoms = os.path.join(cwd, \"test_notebooks/energies_per_atom.txt\")\n",
    "\n",
    "# Open pickle files with the updated file paths\n",
    "with open(file_path_2b, 'rb') as pickle_file:\n",
    "    pd_2b = pickle.load(pickle_file)\n",
    "\n",
    "with open(file_path_3b, 'rb') as pickle_file:\n",
    "    pd_3b = pickle.load(pickle_file)\n",
    "\n",
    "with open(file_path_4b, 'rb') as pickle_file:\n",
    "    pd_4b = pickle.load(pickle_file)\n",
    "\n",
    "with open(file_path_labels, 'rb') as pickle_file:\n",
    "    labels = pickle.load(pickle_file)\n",
    "\n",
    "natom_list = []\n",
    "\n",
    "# Open the text file for reading\n",
    "with open(file_path_natoms, 'r') as file:\n",
    "\n",
    "    # Read the contents of the file\n",
    "    lines = file.readlines()[1:]\n",
    "\n",
    "    # Iterate through each line\n",
    "    for line in lines:\n",
    "\n",
    "        # Split the line into words\n",
    "        words = line.split()\n",
    "        natoms = line.split(\"|\")[1].strip()\n",
    "\n",
    "        # Extract the last word, assuming it's a number\n",
    "        last_number = float(words[-1])\n",
    "        if words[0][-1] == 'z':\n",
    "            print(words[0])\n",
    "            continue\n",
    "        natom_list.append(natoms)\n",
    "\n",
    "natom_list = np.array(natom_list[:-10])\n",
    "\n",
    "# Combine the arrays along the second axis (axis=1)\n",
    "all_array = np.concatenate((pd_2b, pd_3b, pd_4b), axis=2)\n",
    "all_array = all_array.reshape(-1, all_array.shape[2])\n",
    "print(np.shape(all_array))\n",
    "df_fingerprints = pd.DataFrame(all_array)\n",
    "\n",
    "# Define the column labels for each set of columns\n",
    "column_labels_2b = [f'2B_{i}' for i in range(60)]\n",
    "column_labels_3b = [f'3B_{i}' for i in range(60)]\n",
    "column_labels_4b = [f'4B_{i}' for i in range(60)]\n",
    "\n",
    "# Assign the column labels to the DataFrame\n",
    "column_labels = column_labels_2b + column_labels_3b + column_labels_4b\n",
    "df_fingerprints.columns = column_labels\n",
    "\n",
    "# Add a new column \"labels\" to the DataFrame and assign the new vector to it\n",
    "df_fingerprints['labels'] = labels\n",
    "\n",
    "# Calculate the row-wise mean using `mean(axis=1)`\n",
    "row_avg = df_fingerprints.mean(axis=1)\n",
    "\n",
    "# Append the calculated row-wise mean as a new column named \"Pavg\"\n",
    "df_fingerprints['Pavg'] = row_avg\n",
    "\n",
    "# Calculate the row-wise standard deviation using `std(axis=1)`\n",
    "row_std = df_fingerprints.std(axis=1)\n",
    "\n",
    "# Append the calculated row-wise standard deviation as a new column named \"Pstd\"\n",
    "df_fingerprints['Pstd'] = row_std\n",
    "\n",
    "# Append Natoms to Dataframe\n",
    "df_fingerprints['Natoms'] = natom_list\n",
    "\n",
    "# Display the DataFrame with the new column\n",
    "print(df_fingerprints.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
