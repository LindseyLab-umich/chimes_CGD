{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store arrays from each file\n",
    "data_list = []\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "print(os.getcwd())\n",
    "# Specify the directory\n",
    "#directory = \"0.5gcc_1000k_3bS/\"\n",
    "directory = \"/Users/blaubach/chimes_CGD-myLLFork/cluster_analysis/1.0gcc_2000K_3B_graphs/1.0gcc_2000K_3B_graphs/1.0gcc_2000k_3bS/\"\n",
    "#directory = \"/Users/blaubach/chimes_CGD-myLLFork/cluster_analysis/2.0gcc_6000K_3B_graphs/2.0gcc_6000k_3bS/\"\n",
    "# Set the desired subsample size\n",
    "subsample_size = 1000\n",
    "# Loop over the range of integers from 50 to 74\n",
    "for i in range(75, 100):\n",
    "    # Generate the filename\n",
    "    filename = f'{directory}00{i}.3b_clu-s.txt'\n",
    "    \n",
    "    try:\n",
    "        # Read the data from the file and append it to the list\n",
    "        data = np.loadtxt(filename)\n",
    "        sort_data = np.sort(data, axis=1)\n",
    "\n",
    "        # Subsample the sorted data using random indices\n",
    "        random_indices = np.random.choice(sort_data.shape[0], size=subsample_size, replace=False)\n",
    "        subsampled_data = sort_data[random_indices, :]\n",
    "        \n",
    "        # data_list.append(sort_data) # Account for graph invariance\n",
    "        data_list.append(subsampled_data)  # Account for graph invariance\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filename}\")\n",
    "\n",
    "# Concatenate the list of arrays along axis 0 (rows)\n",
    "concat_data = np.concatenate(data_list, axis=0)\n",
    "\n",
    "\n",
    "# Print the shape of concatenated data\n",
    "print(\"Shape:\", np.shape(concat_data))\n",
    "concat_data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
